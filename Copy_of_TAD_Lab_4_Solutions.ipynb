{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Copy of TAD Lab 4 Solutions.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [
        "D7Ntn894nap0",
        "RB8CdPx9LiKy"
      ],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/talamoin/Rango/blob/master/Copy_of_TAD_Lab_4_Solutions.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "metadata": {
        "id": "cl3cfQa7qdSR",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Lab 4: Word Vector representations\n",
        "\n",
        "In this week's lab, we'll explore dense word vector representations.\n",
        "\n",
        "*   Use word vectors to explore word meaning (similar words, analogies, and what does not belong)\n",
        "*   Build a word2vec model of Reddit data\n",
        "*   Use dense vector word representations to model documents with doc2vec\n",
        "* Evaluate the quality of word embedding models\n"
      ]
    },
    {
      "metadata": {
        "id": "xXlWDEnqOtk4",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Glove embeddings\n",
        "\n",
        "[GloVe: Global Vectors for Word Representation](https://nlp.stanford.edu/projects/glove/) developed at Stanford are another way of creating word embeddings.  These dense vectors are trained using sparse global word co-occurrence vectors. \n",
        "\n",
        "The website provides pre-trained word embeddings from a variety of sources. We'll be using the 6B collection, trained on Wikipedia and a large collection of news documents.  We'll be using a vector representation of size 200, but the pretrained embeddings are also available in other sizes.\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "metadata": {
        "id": "nqWvzaBEw3JW",
        "colab_type": "code",
        "outputId": "5c5322d7-4313-4514-f89d-72d0b251da19",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 61
        }
      },
      "cell_type": "code",
      "source": [
        "local_file = \"glove.6B.200d_gensim.txt.gz\"\n",
        "!gsutil cp  gs://textasdata/glove.6B.200d_gensim.txt.gz $local_file "
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Copying gs://textasdata/glove.6B.200d_gensim.txt.gz...\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "OutT1R5E306G",
        "colab_type": "code",
        "outputId": "0c59e04d-0bc7-48c4-b0ea-7d17485519ab",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 462
        }
      },
      "cell_type": "code",
      "source": [
        "#!pip install 'gensim==3.2.0'\n",
        "!pip install --upgrade gensim\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting gensim\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/d7/b9/6c93685bed0026b6a1cce55ab173f6b617f6db0d1325d25489c2fd43e711/gensim-3.7.1-cp36-cp36m-manylinux1_x86_64.whl (24.2MB)\n",
            "\u001b[K    100% |████████████████████████████████| 24.2MB 1.9MB/s \n",
            "\u001b[?25hRequirement already satisfied, skipping upgrade: six>=1.5.0 in /usr/local/lib/python3.6/dist-packages (from gensim) (1.11.0)\n",
            "Requirement already satisfied, skipping upgrade: scipy>=0.18.1 in /usr/local/lib/python3.6/dist-packages (from gensim) (1.1.0)\n",
            "Requirement already satisfied, skipping upgrade: numpy>=1.11.3 in /usr/local/lib/python3.6/dist-packages (from gensim) (1.14.6)\n",
            "Requirement already satisfied, skipping upgrade: smart-open>=1.7.0 in /usr/local/lib/python3.6/dist-packages (from gensim) (1.8.0)\n",
            "Requirement already satisfied, skipping upgrade: boto>=2.32 in /usr/local/lib/python3.6/dist-packages (from smart-open>=1.7.0->gensim) (2.49.0)\n",
            "Requirement already satisfied, skipping upgrade: bz2file in /usr/local/lib/python3.6/dist-packages (from smart-open>=1.7.0->gensim) (0.98)\n",
            "Requirement already satisfied, skipping upgrade: requests in /usr/local/lib/python3.6/dist-packages (from smart-open>=1.7.0->gensim) (2.18.4)\n",
            "Requirement already satisfied, skipping upgrade: boto3 in /usr/local/lib/python3.6/dist-packages (from smart-open>=1.7.0->gensim) (1.9.86)\n",
            "Requirement already satisfied, skipping upgrade: urllib3<1.23,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests->smart-open>=1.7.0->gensim) (1.22)\n",
            "Requirement already satisfied, skipping upgrade: chardet<3.1.0,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->smart-open>=1.7.0->gensim) (3.0.4)\n",
            "Requirement already satisfied, skipping upgrade: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests->smart-open>=1.7.0->gensim) (2018.11.29)\n",
            "Requirement already satisfied, skipping upgrade: idna<2.7,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->smart-open>=1.7.0->gensim) (2.6)\n",
            "Requirement already satisfied, skipping upgrade: jmespath<1.0.0,>=0.7.1 in /usr/local/lib/python3.6/dist-packages (from boto3->smart-open>=1.7.0->gensim) (0.9.3)\n",
            "Requirement already satisfied, skipping upgrade: s3transfer<0.2.0,>=0.1.10 in /usr/local/lib/python3.6/dist-packages (from boto3->smart-open>=1.7.0->gensim) (0.1.13)\n",
            "Requirement already satisfied, skipping upgrade: botocore<1.13.0,>=1.12.86 in /usr/local/lib/python3.6/dist-packages (from boto3->smart-open>=1.7.0->gensim) (1.12.86)\n",
            "Requirement already satisfied, skipping upgrade: python-dateutil<3.0.0,>=2.1; python_version >= \"2.7\" in /usr/local/lib/python3.6/dist-packages (from botocore<1.13.0,>=1.12.86->boto3->smart-open>=1.7.0->gensim) (2.5.3)\n",
            "Requirement already satisfied, skipping upgrade: docutils>=0.10 in /usr/local/lib/python3.6/dist-packages (from botocore<1.13.0,>=1.12.86->boto3->smart-open>=1.7.0->gensim) (0.14)\n",
            "Installing collected packages: gensim\n",
            "  Found existing installation: gensim 3.6.0\n",
            "    Uninstalling gensim-3.6.0:\n",
            "      Successfully uninstalled gensim-3.6.0\n",
            "Successfully installed gensim-3.7.1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "7cBl41_kzPUP",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Note: Loading the glove vectors takes approximately 1 minute in Colab."
      ]
    },
    {
      "metadata": {
        "id": "40cAq2b5HPEb",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from gensim.models.keyedvectors import KeyedVectors\n",
        "glove_model = KeyedVectors.load_word2vec_format(\"glove.6B.200d_gensim.txt.gz\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "clzxxvv9zZlk",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Warmup: Read the Gensim documentation on [KeyedVectors](https://radimrehurek.com/gensim/models/keyedvectors.html) for working with pre-trained word embeedings.  If you want to go deeper on how Gensim works, you can read the [source code](https://github.com/RaRe-Technologies/gensim/blob/develop/gensim/models/keyedvectors.py).\n",
        "\n",
        "**Note:** The GLOVE embeddings are unigrams that have been normalized (lowercased). Word lookups on the vectors need to be the same or the lookups will fail. Not all words may be in the vector, these are OOV words that would be ignored."
      ]
    },
    {
      "metadata": {
        "id": "4B-TT8v_1geu",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "####Exercise:\n",
        "* Use the gensim API to find the 10 most similar words by cosine similarity\n",
        "* Use postive words \"university\" and \"glasgow\". \n",
        "* Beyond these words, experiment with other words as positive seeds."
      ]
    },
    {
      "metadata": {
        "id": "ruLdEQk9ou75",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "ugIMDMxSy8ro",
        "colab_type": "code",
        "outputId": "be30f7d6-6b07-4cdc-a11f-4f404dc80300",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 187
        }
      },
      "cell_type": "code",
      "source": [
        "# Solution\n",
        "glove_model.most_similar(positive=['university', 'glasgow'])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('edinburgh', 0.724178671836853),\n",
              " ('college', 0.635900616645813),\n",
              " ('professor', 0.6125119924545288),\n",
              " ('graduate', 0.602368950843811),\n",
              " ('oxford', 0.5923569202423096),\n",
              " ('campus', 0.5879751443862915),\n",
              " ('cambridge', 0.5866643190383911),\n",
              " ('birmingham', 0.5773380994796753),\n",
              " ('melbourne', 0.5755240321159363),\n",
              " ('graduated', 0.574782133102417)]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "metadata": {
        "id": "lmNFWB4JobDF",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Try your own!"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Y9bgwU9y18iP",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "#### Exercise: \n",
        "\n",
        "* Create a function `word_anology` that uses cosine to solve problem analogy A is to B =  BLANK  is to C?  (e.g. Paris is to France = ___ is to England)\n",
        "* It should take a parameter, `k`, the number of possible answers to return.\n",
        "\n",
        "**Hint**: Formulate this with addition and subtraction with the word vectors. "
      ]
    },
    {
      "metadata": {
        "id": "kCHGf1VxhArk",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def word_analogy(word_a, word_b, word_c, k=5):\n",
        "    \"\"\"\n",
        "    Function that solves problem analogy word_a to word_b = word_c to ?\n",
        "    @param word_a, word_b, word_c: string\n",
        "    @param k: top k candidates to return\n",
        "    \"\"\"\n",
        "    # YOUR CODE HERE"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "shQBEmdl9ebg",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Solution \n",
        "def word_analogy(word_a, word_b, word_c, k=5):\n",
        "    \"\"\"\n",
        "    Function that solves problem analogy word_a to word_b = word_c to ?\n",
        "    @param word_a, word_b, word_c: string\n",
        "    @param k: top k candidates to return\n",
        "    \"\"\"\n",
        "    positive_words = [word_a, word_c]\n",
        "    negative_words = [word_b]\n",
        "    return glove_model.most_similar(positive=positive_words, negative=negative_words, topn=k)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "RHb1a6czPUXS",
        "colab_type": "code",
        "outputId": "6b524d36-4dc5-4254-c413-1549d32b0511",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 102
        }
      },
      "cell_type": "code",
      "source": [
        "word_analogy(\"london\", \"england\", \"scotland\")"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('glasgow', 0.6496507525444031),\n",
              " ('edinburgh', 0.6335984468460083),\n",
              " ('scottish', 0.5466927289962769),\n",
              " ('dublin', 0.5138986110687256),\n",
              " ('britain', 0.4929892420768738)]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "metadata": {
        "id": "6DV2_u0kAxhM",
        "colab_type": "code",
        "outputId": "f6b36457-5bb0-4972-d31c-8250d0a7973b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 102
        }
      },
      "cell_type": "code",
      "source": [
        "word_analogy(\"fish\", \"water\", \"soil\")"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('species', 0.506380021572113),\n",
              " ('soils', 0.480771541595459),\n",
              " ('shellfish', 0.46889352798461914),\n",
              " ('invertebrates', 0.4687715768814087),\n",
              " ('organisms', 0.45920252799987793)]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "metadata": {
        "id": "nrjJev7gCSbn",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Play with a few of your own word analogies. "
      ]
    },
    {
      "metadata": {
        "id": "VbcUvKSyDRiy",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "We will now play another game: \"Which of these things does not belong\". \n",
        "\n",
        "### Optional Exercise \n",
        "* Implement a function,  `doesnt_match `\n",
        "* Take a series of word as input, returns the word farthest from the mean (average) embedding by cosine similarity. \n",
        "\n",
        "**Hints**:\n",
        " - np.mean(vectors, axis=0) performs element-wise averages\n",
        " [20, 30]\n",
        " [10, 10]\n",
        " = [15, 20]\n",
        " - See  `cosine_similarities` built in to the  `glove_model ` (KeyedVector) object. \n",
        " \n"
      ]
    },
    {
      "metadata": {
        "id": "eAuWymiHD1pQ",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "BYyyzG8V-DTz",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "def doesnt_match(words):\n",
        "  filtered_words = [word for word in words if word in glove_model]\n",
        "  vectors = [glove_model.word_vec(word, use_norm=True) for word in filtered_words]\n",
        "  mean = np.mean(vectors, axis=0)\n",
        "  distances = glove_model.cosine_similarities(mean, vectors)\n",
        "  return sorted(zip(distances, filtered_words))[0][1]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "xG5y1VifyHCO",
        "colab_type": "code",
        "outputId": "edd7e107-7df0-4bea-b339-5f294b979451",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "doesnt_match(\"apple pear orange car\".split())\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'car'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "metadata": {
        "id": "2-Lcy0j0ULCY",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "_KKDk1Two6Od",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Try this out with another series of words and see if it works!"
      ]
    },
    {
      "metadata": {
        "id": "pbb1pQGSChZt",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Train a Reddit Word2Vec Model"
      ]
    },
    {
      "metadata": {
        "id": "ArN6SGUFqlWI",
        "colab_type": "code",
        "outputId": "f37fc597-48f2-41c7-a8ce-7865c236c5bc",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        }
      },
      "cell_type": "code",
      "source": [
        "local_file = \"coarse_discourse_dump_reddit.json\"\n",
        "\n",
        "!gsutil cp gs://textasdata/coarse_discourse_dump_reddit.json $local_file"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Copying gs://textasdata/coarse_discourse_dump_reddit.json...\n",
            "/ [1 files][ 78.5 MiB/ 78.5 MiB]                                                \n",
            "Operation completed over 1 objects/78.5 MiB.                                     \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "BYgoXyC-EVTd",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#!python -m spacy download en\n",
        "\n",
        "import spacy\n",
        "\n",
        "# Load the small english model. \n",
        "# Disable the advanced NLP features in the pipeline for efficiency.\n",
        "nlp = spacy.load('en_core_web_sm', disable=['ner'])\n",
        "nlp.remove_pipe('tagger')\n",
        "nlp.remove_pipe('parser')\n",
        "\n",
        "#@Tokenize\n",
        "def spacy_tokenize(string):\n",
        "  tokens = list()\n",
        "  doc = nlp(string)\n",
        "  for token in doc:\n",
        "    tokens.append(token)\n",
        "  return tokens\n",
        "\n",
        "#@Normalize\n",
        "def normalize(tokens):\n",
        "  normalized_tokens = list()\n",
        "  for token in tokens:\n",
        "    if (token.is_alpha or token.is_digit):\n",
        "      normalized = token.text.lower().strip()\n",
        "      normalized_tokens.append(normalized)\n",
        "  return normalized_tokens\n",
        "\n",
        "#@Tokenize and normalize\n",
        "def tokenize_normalize(string):\n",
        "  return normalize(spacy_tokenize(string))  "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "DtHo_snoEuD3",
        "colab_type": "code",
        "outputId": "42cd157a-3da9-4f86-d95c-c3a3878f02da",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "import json\n",
        "import pandas as pd\n",
        "\n",
        "posts = list()\n",
        "\n",
        "# If the dataset is too large, you can load a subset of the posts.\n",
        "post_limit = 100000000\n",
        "\n",
        "# Construct a dataframe, by opening the JSON file line-by-line\n",
        "with open(local_file) as jsonfile:\n",
        "  for i, line in enumerate(jsonfile):\n",
        "    thread = json.loads(line)\n",
        "    if (len(posts) > post_limit):\n",
        "      break\n",
        "      \n",
        "    for post in thread['posts']:\n",
        "      posts.append((thread['subreddit'], thread['title'], thread['url'],\n",
        "                        post['id'], post.get('author', \"\"), post.get('body', \"\")))\n",
        "print(len(posts))\n",
        "\n",
        "labels = ['subreddit', 'title', 'id', 'url', 'author', 'body']\n",
        "post_frame = pd.DataFrame(posts, columns=labels)\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "110595\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "fMfcZ4nFq-Zn",
        "colab_type": "code",
        "outputId": "04cc41ab-bab0-44b5-be80-3523c776b569",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "# Use the tokenizer to extract all tokens from the body of the posts.\n",
        "# Flatten the tokens in the post into a single list of all the tokens.\n",
        "import itertools\n",
        "all_tokens = []\n",
        "all_posts_tokenized = post_frame.body.apply(tokenize_normalize)\n",
        "all_tokens = list(itertools.chain.from_iterable(all_posts_tokenized))\n",
        "print(\"Num tokens: \", len(all_tokens))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Num tokens:  4500590\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "I1RPfRl26Idg",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Gensim word2vec model ###\n",
        "\n",
        "In this section, we'll train a word2vec model on the reddit data using [Gensim](https://radimrehurek.com/gensim/index.html). Gensim is a widely used 'topic modeling' library that is used for various word and document similarities in Python.\n",
        "\n",
        "You will need to refer to the documentation of Gensim's [Word2Vec Model](https://radimrehurek.com/gensim/models/word2vec.html).\n",
        "\n",
        "Some of the important parameters:\n",
        "*   `size`: Number of dimensions for word embedding model\n",
        "*   `window`: Number of context words to observe in each direction\n",
        "*   `min_count`: Minimum frequency for words included in model\n",
        "*   `sg` (Skip-Gram): '0' indicates CBOW model; '1' indicates Skip-Gram\n",
        "*   `alpha`: Learning rate (initial); prevents model from over-correcting, enables finer tuning\n",
        "*   `iterations`: Number of passes through dataset\n",
        "*   `batch_words`: Number of words to sample from data during each pass\n"
      ]
    },
    {
      "metadata": {
        "id": "3Bc0DndejtTy",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "\n",
        "Note: Training the model should take less than 1-2 minutes in colab.\n",
        "\n",
        "**Exercise**: \n",
        "- Train a CBOW model on `all_posts_tokenized`\n",
        "- Add the correct parameters to gensim and train a model\n",
        "- Paramters: `window = 5, dimensions = 50, min_count=5, alpha=0.025`,  `size = 50`, `batch_words=10000` to have a batch size of 10k. \n",
        "\n",
        "We're training a CBOW model because on small collections, like the Reddit data we're using, CBOW is more effective than Skip-gram. Skip-gram models usually perform better on larger datasets. \n",
        "\n",
        "We also usually use more than 50 dimensions (typically 100-300 or more).\n"
      ]
    },
    {
      "metadata": {
        "id": "p3YEVvG5iLo1",
        "colab_type": "code",
        "outputId": "75db11b5-21d6-4323-c0ac-2a34a5bb437f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 129
        }
      },
      "cell_type": "code",
      "source": [
        "import gensim\n",
        "import time\n",
        "\n",
        "t0 = time.time()\n",
        "model = gensim.models.Word2Vec(all_posts_tokenized ...\n",
        "print (\"done in %.02f s\" % (time.time() - t0))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "error",
          "ename": "SyntaxError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-16-1b101251e405>\"\u001b[0;36m, line \u001b[0;32m5\u001b[0m\n\u001b[0;31m    model = gensim.models.Word2Vec(all_posts_tokenized ...\u001b[0m\n\u001b[0m                                                         ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
          ]
        }
      ]
    },
    {
      "metadata": {
        "id": "QTElDC5p6HlO",
        "colab_type": "code",
        "outputId": "e4afe71f-27e4-4beb-dcef-4f70eac84b22",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "#Solution\n",
        "\n",
        "import gensim\n",
        "import time\n",
        "\n",
        "t0 = time.time()\n",
        "model = gensim.models.Word2Vec(all_posts_tokenized, size=50, window=5, \\\n",
        "                               min_count=5, sg=0, alpha=0.025, iter=10, batch_words=10000)\n",
        "print (\"done in %.02f s\" % (time.time() - t0))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "done in 30.26 s\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "ofy4xuhrLU3_",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "How well does the model work?  \n",
        "\n",
        "Let's compute the cosine similarity between several combinations of vectors to see if they make sense. \n",
        "Use the gensim [word2vec API](https://radimrehurek.com/gensim/models/word2vec.html).\n",
        "\n",
        "**Exercise:** Find the similarities between 'man' and 'woman'.\n"
      ]
    },
    {
      "metadata": {
        "id": "NgDGXAMrjchg",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "A4lgQ80D9e4L",
        "colab_type": "code",
        "outputId": "1a478897-1d84-4e61-d1d4-547084486282",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "#solution \n",
        "model.wv.similarity ('man', 'woman')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.6984612"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 18
        }
      ]
    },
    {
      "metadata": {
        "id": "JzuXJAEULQcG",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Now, do the same for 'woman' and girl'.\n"
      ]
    },
    {
      "metadata": {
        "id": "gKJijkY5jobP",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "eipDbQm9-Aqb",
        "colab_type": "code",
        "outputId": "49cff7a4-b126-4bea-d7f4-df9355aabcf9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "#solution\n",
        "model.wv.similarity('woman', 'girl')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.85400087"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 19
        }
      ]
    },
    {
      "metadata": {
        "id": "pKCFYA8RinLC",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Which one is more similar?  Is this what you expect?\n",
        "\n",
        "Let's dig deeper and look at months."
      ]
    },
    {
      "metadata": {
        "id": "_rXLjtYALYZl",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Pick a month of the year.  What are the most similar 11 words?"
      ]
    },
    {
      "metadata": {
        "id": "UfbV_f1_jwEo",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "nAlhD5sC9lsf",
        "colab_type": "code",
        "outputId": "7699a6b6-7f8a-4164-a5d5-94ae99127225",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 357
        }
      },
      "cell_type": "code",
      "source": [
        "#solution \n",
        "model.wv.similar_by_word ('june', topn = 20)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('july', 0.9372295141220093),\n",
              " ('november', 0.9217525124549866),\n",
              " ('december', 0.9171973466873169),\n",
              " ('march', 0.9165485501289368),\n",
              " ('april', 0.9133614301681519),\n",
              " ('february', 0.904845654964447),\n",
              " ('2012', 0.9046369791030884),\n",
              " ('september', 0.9045284390449524),\n",
              " ('january', 0.9044721126556396),\n",
              " ('october', 0.9038004279136658),\n",
              " ('2013', 0.8952332139015198),\n",
              " ('2011', 0.8763068914413452),\n",
              " ('august', 0.8746588230133057),\n",
              " ('2015', 0.8627378940582275),\n",
              " ('2014', 0.8624193072319031),\n",
              " ('wednesday', 0.8455826044082642),\n",
              " ('2016', 0.8430826663970947),\n",
              " ('finals', 0.8382493257522583),\n",
              " ('2010', 0.8290757536888123),\n",
              " ('monday', 0.824270486831665)]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 20
        }
      ]
    },
    {
      "metadata": {
        "id": "9zX89Vyeivpb",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "- What month is missing? \n",
        "- Why do you think this could be given what we discussed in lecture?"
      ]
    },
    {
      "metadata": {
        "id": "Ec0qjPWWF0Uy",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Word vector document representations"
      ]
    },
    {
      "metadata": {
        "id": "YyRukZ5ChHUD",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "We've looked at how to represent words with dense vectors. Let's now apply this by using dense word vectors to represent documents. \n",
        "\n",
        "\n",
        "Recall from Lecture 1: We typically represent each document as a vector, with one dimension for each word in the dictionary (i.e. each document's vector is $|V|$). How can we expand this to deal with word embeddings? We could represent each term occurrence by the $|D|$ dimensions of its word embedding vector - i.e. where each word occurrence is represented with the vector for that word. \n",
        "\n",
        "\n",
        "However, this would lead to a very large document representation (a vector of $|D| * |V|$ in our case)! Instead, one approach is to combine the dense vector representations.\n",
        "\n",
        "\n",
        "In this part of the lab, we'll experiment with different ways of combining word vectors Each document will be represented by a single $|D|$ dimensional vector that is the combination of all of its word vectors.\n",
        "\n",
        "We could combine the vectors in different ways:\n",
        "*   Take the average of each dimension\n",
        "*   Take the min or max of each dimension\n",
        "\n",
        "### A note on SKLearn: BaseEstimator interface\n",
        "The root of the API is an `Estimator`, broadly any object that can learn from data. The primary `Estimator` objects implement classifiers, regressors, or clustering algorithms. However, they can also include a wide array of data manipulation, from dimensionality reduction to feature extraction from raw data. The `Estimator` essentially serves as an interface, and classes that implement `Estimator` functionality must have two methods—`fit` and `predict`. \n",
        "\n",
        "A `Transformer` is a special type of `Estimator` that creates a new dataset from an old one based on rules that it has learned from the fitting process. it follows  `fit` and `transform`.\n",
        "\n",
        "As you've seen, we'll use these extensively.  In many cases it's easier to create your own Estimator/Transformer for custom applications.\n",
        "\n",
        "\n"
      ]
    },
    {
      "metadata": {
        "id": "kpmZNj-7NzRf",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from sklearn.base import BaseEstimator\n",
        "\n",
        "class Estimator(BaseEstimator):\n",
        "\n",
        "    def fit(self, X, y=None):\n",
        "        \"\"\"\n",
        "        Accept input data, X, and optional target data, y. Returns self.\n",
        "        \"\"\"\n",
        "        return self\n",
        "\n",
        "    def predict(self, X):\n",
        "        \"\"\"\n",
        "        Accept input data, X and return a vector of predictions for each row.\n",
        "        \"\"\"\n",
        "        return yhat\n",
        "      \n",
        "from sklearn.base import TransformerMixin\n",
        "\n",
        "class Transfomer(BaseEstimator, TransformerMixin):\n",
        "\n",
        "    def fit(self, X, y=None):\n",
        "        \"\"\"\n",
        "        Learn how to transform data based on input data, X.\n",
        "        \"\"\"\n",
        "        return self\n",
        "\n",
        "    def transform(self, X):\n",
        "        \"\"\"\n",
        "        Transform X into a new dataset, Xprime and return it.\n",
        "        \"\"\"\n",
        "        return Xprime"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "ukKN1aqNN5-f",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "#### Exercise:\n",
        "Create a SKlearn wrapper (Transformer) around Gensim's W2V features to create a document representation that's the average of the word vectors.\n",
        "\n",
        "* Complete the implementation of Transform \n",
        "* Input is `X`: a vector of documents -> list of tokens\n",
        "* Tokenize each document to produce the tokens\n",
        "* Ignore OOV words \n",
        "* Take the average (mean) of the embeddings for each word word in the document\n",
        "\n",
        "**Reminder** Transform takes a document-feature matrix as input.  Assume that X is a vector of documents each containing a single string (requires tokenization).  \n",
        "\n",
        "As in the `doesnt_match` above, use numpy for the vector arithmetic. \n",
        "\n",
        "**Hints** \n",
        "- If all words in the document are UNK, return a $|D|$ dimensional vector of 0s.\n",
        "- This is particularly elegant with nested list comprehensions (documents, tokens)\n",
        "\n"
      ]
    },
    {
      "metadata": {
        "id": "4szpAvfnq-qj",
        "colab_type": "code",
        "outputId": "8cb70754-f165-4ce5-d2a6-191b13d38ee8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 129
        }
      },
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "from sklearn.base import BaseEstimator, VectorizerMixin\n",
        "\n",
        "class AverageEmbeddingVectorizer(BaseEstimator, VectorizerMixin):\n",
        "  \n",
        "    def __init__(self, embedding_model):\n",
        "        self.embedding = embedding_model\n",
        "        self.dimension = embedding_model.vector_size\n",
        "\n",
        "    def fit(self, X, y):\n",
        "      # Nothing is required here. No collection properties are needed.\n",
        "      return self\n",
        "      \n",
        "    def transform(self, X):\n",
        "      # Input: X: an iterable of documents that have been tokenized.\n",
        "      # Example of input with two documents: \n",
        "      # [[\"the\", \"cat\", \"ran\"], [\"the\", \"cat\", \"jumped\"]]\n",
        "      # Output: a numpy array of vectors, one for each document.  Each vector\n",
        "      # is the mean of the vectors of each word in the document. \n",
        "      # Hint: It may require a nested loop / for comprehension.\n",
        "      # Be sure to skip OOV terms. Return 0 if no words are in the vocabulary.\n",
        "      return <YOUR CODE HERE>"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "error",
          "ename": "SyntaxError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-21-4caeb50e06a3>\"\u001b[0;36m, line \u001b[0;32m23\u001b[0m\n\u001b[0;31m    return <YOUR CODE HERE>\u001b[0m\n\u001b[0m           ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
          ]
        }
      ]
    },
    {
      "metadata": {
        "id": "OhsuyEflOMZF",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#Solution\n",
        "\n",
        "import numpy as np\n",
        "\n",
        "from sklearn.base import BaseEstimator, VectorizerMixin\n",
        "\n",
        "class AverageEmbeddingVectorizer(BaseEstimator, VectorizerMixin):\n",
        "    def __init__(self, embedding_model):\n",
        "        self.embedding = embedding_model\n",
        "        self.dimension = embedding_model.vector_size\n",
        "\n",
        "    def fit(self, X, y):\n",
        "        return self\n",
        "      \n",
        "    def transform(self, X):  \n",
        "      # Skip OOV terms. Return 0 if no words are in the vocabulary.\n",
        "      #print (X)\n",
        "      return np.array([ \n",
        "          np.mean([self.embedding[token] for token in doc if token in self.embedding]\n",
        "                or [np.zeros(self.dimension)], axis=0)\n",
        "          for doc in X\n",
        "      ])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "6SIxIQY7RdA7",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Use a vectorizer with the Glove vectors and Reddit w2v vectors.  This will \n",
        "# allow us to easily compare them.\n",
        "reddit_vectorizer = AverageEmbeddingVectorizer(model)\n",
        "glove_vectorizer = AverageEmbeddingVectorizer(glove_model)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "OBPR1VWDnPCQ",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Compare the reddit and glove vectorizers for the same vector of tokens. What's different (besides the fact that the numbers are different)?\n"
      ]
    },
    {
      "metadata": {
        "id": "AUrTFLXTimF0",
        "colab_type": "code",
        "outputId": "295aa50b-82d4-4c67-c6b7-454afffb5beb",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1108
        }
      },
      "cell_type": "code",
      "source": [
        "doc = tokenize_normalize('watch the cat chase the dog')\n",
        "X = [doc]\n",
        "print(\"Glove:\")\n",
        "print(glove_vectorizer.transform(X))\n",
        "print(\"Reddit:\")\n",
        "print(reddit_vectorizer.transform(X))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Glove:\n",
            "[[ 1.63113698e-01 -1.24406993e-01 -2.57880479e-01 -2.96022981e-01\n",
            "  -1.29645661e-01 -7.15244338e-02 -4.49286669e-01 -4.48928215e-02\n",
            "  -5.03983349e-02  6.87483326e-03  1.11675680e-01 -4.64133322e-02\n",
            "   7.09949955e-02  1.03816658e-01  1.17365003e-01 -2.29881659e-01\n",
            "  -2.09559992e-01  3.26450378e-01 -2.05681667e-01  1.63859665e-01\n",
            "   1.66395500e-01  1.89386165e+00  4.32740360e-01 -1.79530323e-01\n",
            "   5.37426658e-02 -2.50137657e-01  1.44816652e-01  6.11399896e-02\n",
            "  -9.75496173e-02 -1.12716168e-01  1.23511672e-01  2.49949992e-02\n",
            "  -5.09999990e-02 -3.18212181e-01  1.47144005e-01 -3.21818322e-01\n",
            "  -4.75318521e-01 -3.23068388e-02 -2.82053351e-02 -2.19905213e-01\n",
            "   7.86913335e-02  3.43749970e-02  1.87430084e-02  5.25139987e-01\n",
            "  -1.93519652e-01  6.71821654e-01  5.02445042e-01 -8.71263370e-02\n",
            "   2.69181490e-01  4.74094152e-01 -1.04417168e-01  9.11586657e-02\n",
            "   2.13824019e-01 -7.50293210e-02  4.01116647e-02 -3.11411116e-02\n",
            "  -2.57424980e-01  1.16599999e-01 -1.16294362e-01  2.63558298e-01\n",
            "   3.36519964e-02 -1.29982576e-01 -4.67010021e-01 -1.10983197e-03\n",
            "   1.09883249e-02 -1.51343336e-02 -7.22709969e-02 -1.67322680e-01\n",
            "   2.38520339e-01  6.75516725e-02  2.95983821e-01 -9.83379781e-02\n",
            "  -4.47033346e-02  2.56633848e-01  2.00041663e-02  1.89281002e-01\n",
            "  -2.91627318e-01 -1.88499968e-02 -1.33723365e-02 -3.15283276e-02\n",
            "  -2.13961732e-02 -3.73448245e-02  7.06566647e-02 -1.93447158e-01\n",
            "  -2.04665065e-01  2.79996637e-02 -3.29085022e-01 -2.52016664e-01\n",
            "   4.44980025e-01 -9.47073281e-01 -2.72471339e-01  8.21063370e-02\n",
            "   1.69541836e-01  1.99673340e-01  1.50510654e-01  1.57265320e-01\n",
            "  -3.94716812e-03 -4.81888354e-02  2.05256622e-02 -4.89399992e-02\n",
            "   1.00022174e-01 -8.23358372e-02 -1.44512847e-01 -3.52263339e-02\n",
            "  -2.07354665e-01 -5.98646849e-02  1.66734993e-01  9.71121609e-01\n",
            "   2.63375025e-02 -5.77296317e-02  1.79170683e-01 -1.44966662e-01\n",
            "  -1.10141031e-01  4.62669991e-02 -1.69731677e-01  6.90666214e-02\n",
            "  -7.89050683e-02  7.89316595e-02 -3.73519987e-01 -1.64700001e-02\n",
            "   3.54656667e-01 -2.07851663e-01 -5.44196628e-02  7.53453299e-02\n",
            "   3.31116468e-01 -4.37618375e-01 -1.01077341e-01  1.99015006e-01\n",
            "   2.15172008e-01  3.54329735e-04 -1.51116652e-02 -1.11584999e-01\n",
            "   3.71267319e-01 -1.89984486e-01  3.61724980e-02 -1.94302678e-01\n",
            "   1.91883564e-01 -2.26310179e-01 -1.21588372e-02 -7.16866627e-02\n",
            "  -1.03785001e-01  5.73366694e-02  2.95601696e-01  3.08296625e-02\n",
            "   1.10864007e+00  1.79811671e-01 -3.69603299e-02 -3.48753333e-01\n",
            "   2.37338886e-01  2.82257169e-01  2.71626651e-01  4.30338293e-01\n",
            "  -1.89611986e-01  3.13718244e-02  3.55804324e-01  4.39804673e-01\n",
            "  -7.75316730e-02  3.58010046e-02 -5.68994999e-01 -4.66095001e-01\n",
            "   4.79361750e-02  1.06888331e-01  7.24566653e-02 -3.00173331e-02\n",
            "   3.08514331e-02 -1.57700673e-01 -1.55031666e-01 -5.35561554e-02\n",
            "  -2.71202832e-01  9.02520046e-02  8.06665886e-03  1.48406669e-01\n",
            "   7.57227615e-02 -1.24344498e-01  1.34234831e-01  9.31720734e-02\n",
            "   4.22143340e-02 -4.01017666e-01 -1.19084172e-01  1.47073671e-01\n",
            "   1.16270828e+00 -1.81122348e-01 -1.79767847e-01 -9.03350040e-02\n",
            "  -4.21111345e-01 -2.83079982e-01  1.09348424e-01  1.08411662e-01\n",
            "   3.47339988e-01  4.36871797e-02  8.59869942e-02 -7.24448338e-02\n",
            "  -6.31976649e-02  8.60182941e-03 -2.02745318e-01  2.88328648e-01\n",
            "  -6.63018972e-02  3.39100629e-01  1.08036987e-01  5.75783364e-02]]\n",
            "Reddit:\n",
            "[[-0.09628513  0.28669405  0.12134994 -0.6618787   0.00986617 -0.4567771\n",
            "   0.47221753 -0.6134581  -0.00624714 -0.6501696   0.6397085  -1.1499547\n",
            "   0.07256741  0.8723011  -0.02625113  0.43628255 -0.48085642  0.543242\n",
            "  -0.33198056  0.2370845  -0.00432157 -0.9257638   0.04707597 -0.2350206\n",
            "  -0.11380147  0.01390468  0.63676757  0.36507693  0.22441249  0.3467511\n",
            "  -0.48165107 -0.09826957 -0.29920307  0.03948303  0.5645594  -0.58036476\n",
            "   0.4367908   0.44325623 -0.11902825  0.6674731   0.47688687  0.49615714\n",
            "  -1.0093853   0.02688456  0.67377114  1.0623326  -0.27224028  0.35538292\n",
            "   0.31112126 -0.6518617 ]]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:18: DeprecationWarning: Call to deprecated `__contains__` (Method will be removed in 4.0.0, use self.wv.__contains__() instead).\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:18: DeprecationWarning: Call to deprecated `__getitem__` (Method will be removed in 4.0.0, use self.wv.__getitem__() instead).\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "metadata": {
        "id": "5Z73FjdslTSY",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "We can see that the number of dimensions is different, as well as producing very different vector values."
      ]
    },
    {
      "metadata": {
        "id": "Ytu2OnTXXnIC",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Let's process our collection with our embedding vectorizer."
      ]
    },
    {
      "metadata": {
        "id": "fZxy3jM4peZs",
        "colab_type": "code",
        "outputId": "fa834da8-d24b-48a4-b006-512f762f3a05",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 71
        }
      },
      "cell_type": "code",
      "source": [
        "glove_post_vector_matrix = glove_vectorizer.transform(all_posts_tokenized)\n",
        "reddit_post_vector_matrix = reddit_vectorizer.transform(all_posts_tokenized)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:18: DeprecationWarning: Call to deprecated `__contains__` (Method will be removed in 4.0.0, use self.wv.__contains__() instead).\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:18: DeprecationWarning: Call to deprecated `__getitem__` (Method will be removed in 4.0.0, use self.wv.__getitem__() instead).\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "metadata": {
        "id": "_YXyPANmenzw",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "**Word2Vec Questions:** \n",
        "*   Do you expect this would this work well for long documents?  Why or why not?\n",
        "*   What about stopwords or non-informative words? See the optional exercises for ideas on how to improve the vectorizer. \n",
        "*   Averaging word vectors has some disavantages, what happens to word order? \n",
        "\n",
        "Doc2Vec addresses some of these issues.\n"
      ]
    },
    {
      "metadata": {
        "id": "PiUzIS-Gc0lp",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Paragraph embeddings\n",
        "There is an extension to word2vec to learn fixed-length representations of variable length documents, beyond taking a simple average.  Doc2Vec was shown to be effective as a text classification feature as well as paragraph similarity.\n",
        "\n",
        "See Gensim's description of [Doc2Vec](https://radimrehurek.com/gensim/models/doc2vec.html). It was developed at Google Research  by Quoc Le and Tomas Mikolov: “[Distributed Representations of Sentences and Documents](https://arxiv.org/pdf/1405.4053v2.pdf)\". "
      ]
    },
    {
      "metadata": {
        "id": "RaeAmviGcjQc",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import gensim\n",
        "import collections\n",
        "from gensim.models.doc2vec import Doc2Vec, TaggedDocument\n",
        "\n",
        "tagged_documents = [TaggedDocument(words=_d, tags=[i]) for i, _d in enumerate(all_posts_tokenized)]\n",
        "\n",
        "# In the paper they use 400 as the dimensions, may take many more epochs to converge.\n",
        "# The devil is in the details to make these work effectively.\n",
        "d2v_model = gensim.models.doc2vec.Doc2Vec(tagged_documents, vector_size=300, alpha=0.025, min_alpha=0.001, min_count=5, window=8, epochs=10)\n",
        "#vocab = collections.Counter(all_tokens)\n",
        "#d2v_model.build_vocab_from_freq(vocab)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "BbYNnVxLoiFO",
        "colab_type": "code",
        "outputId": "562f0f2a-477f-471d-8f07-9ea6a47d8685",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1309
        }
      },
      "cell_type": "code",
      "source": [
        "d2v_model.docvecs[1]"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([-3.75465453e-02, -1.66634060e-02,  9.36758297e-04, -3.15666310e-02,\n",
              "        1.93500835e-02, -1.97767112e-02, -1.60256717e-02, -1.42481383e-02,\n",
              "       -9.85868555e-03, -9.39203128e-02, -1.88690592e-02,  3.21774483e-02,\n",
              "        3.64510976e-02,  3.12761292e-02, -2.24394929e-02,  2.30064951e-02,\n",
              "       -2.90604006e-03, -1.04736416e-02, -2.64629889e-02,  4.34406884e-02,\n",
              "       -1.04518039e-02, -9.25261248e-03, -3.40506099e-02, -5.98773174e-02,\n",
              "        4.73213335e-03, -1.03457443e-01,  5.29748052e-02,  1.03311269e-02,\n",
              "        4.74952906e-02, -2.51637213e-02,  4.67643663e-02, -3.60898785e-02,\n",
              "       -7.48082921e-02, -5.10024931e-03,  2.54619820e-03, -4.38032262e-02,\n",
              "        3.57788391e-02,  1.46911703e-02, -6.01933263e-02,  7.18586594e-02,\n",
              "        6.00459911e-02,  2.39819270e-02, -6.74296916e-02, -3.37351598e-02,\n",
              "        6.44626766e-02, -3.13020721e-02, -3.30851376e-02, -5.58158755e-02,\n",
              "        1.61181334e-02,  1.16671585e-02,  8.80462751e-02, -6.04063645e-02,\n",
              "        2.57507502e-03, -9.82752722e-03, -7.37896487e-02,  2.04802565e-02,\n",
              "       -2.00721528e-02, -4.71833386e-02, -5.30210696e-02,  4.70854081e-02,\n",
              "        4.57831472e-02,  3.00456844e-02, -4.05195728e-02, -1.24914171e-02,\n",
              "        9.55903064e-03, -6.10077977e-02, -3.35507914e-02,  2.87689809e-02,\n",
              "       -5.56394793e-02,  5.31190783e-02, -4.14599851e-02,  2.20902171e-02,\n",
              "        2.19084211e-02, -8.15287232e-02, -1.16161574e-02,  1.31641869e-02,\n",
              "        7.31275696e-03, -3.16570811e-02,  2.65803766e-02, -7.81836882e-02,\n",
              "       -5.57105318e-02,  2.63541900e-02,  7.09294667e-03,  2.00249776e-02,\n",
              "        7.41939805e-03,  2.21522935e-02,  3.73819983e-03,  2.35653818e-02,\n",
              "        1.83750992e-03,  9.55261216e-02, -3.21899876e-02, -1.00202707e-03,\n",
              "       -2.32558455e-02,  9.66600142e-03, -5.27221104e-03, -4.32047360e-02,\n",
              "        8.27373471e-03, -3.50037180e-02, -3.21002044e-02, -3.89841087e-02,\n",
              "        2.76346132e-02, -3.80185135e-02,  7.51056988e-03,  5.16056791e-02,\n",
              "        3.12125925e-02,  3.79876755e-02,  2.40322016e-02,  9.77545884e-03,\n",
              "        3.06463577e-02, -1.51347117e-02, -1.25490287e-02,  5.29257730e-02,\n",
              "        2.00271159e-02, -3.69016523e-03, -3.42441313e-02, -3.19956243e-02,\n",
              "        9.50117223e-03,  9.09034722e-03,  1.46036223e-02, -8.80583525e-02,\n",
              "       -9.43635255e-02, -2.16352437e-02, -1.15366373e-02,  4.96393768e-03,\n",
              "        3.72987352e-02,  3.80645618e-02, -1.29026715e-02,  4.28834856e-02,\n",
              "        5.40440977e-02, -7.82447457e-02, -9.74023789e-02, -2.33262293e-02,\n",
              "        8.60755704e-03,  2.22896636e-02,  7.60033131e-02, -7.17536197e-04,\n",
              "        1.74275190e-02, -4.07140255e-02, -3.83230001e-02, -5.76704703e-02,\n",
              "       -3.80150080e-02, -4.64093499e-02, -2.43014330e-03,  9.82701126e-03,\n",
              "       -4.52659540e-02,  4.14025970e-02, -4.23629731e-02, -1.91848283e-03,\n",
              "       -1.56044532e-02, -1.36255715e-02, -8.37788135e-02,  2.75990777e-02,\n",
              "        2.88718417e-02,  1.73145216e-02, -2.71649417e-02,  2.90866662e-02,\n",
              "        5.18160537e-02, -6.58926927e-03, -1.29530905e-03,  2.41744891e-02,\n",
              "       -2.99155861e-02, -1.48955146e-02, -1.12286527e-02, -1.83832608e-02,\n",
              "       -2.02617515e-02, -6.55584037e-02, -1.49175599e-02, -7.67799979e-03,\n",
              "       -4.00676243e-02, -2.17977911e-02,  3.26163881e-02, -3.26044597e-02,\n",
              "       -4.89969924e-03,  2.43589608e-03,  3.18036526e-02,  1.90485772e-02,\n",
              "        2.33562216e-02,  2.34479122e-02,  4.86437678e-02, -1.59304179e-02,\n",
              "       -9.63996630e-03,  1.46786664e-02,  7.97884632e-03, -7.70460465e-05,\n",
              "        1.23323931e-03, -2.21944470e-02, -1.61809511e-02,  1.60059165e-02,\n",
              "       -1.81398410e-02, -4.09649275e-02,  9.51821171e-03, -1.69449858e-02,\n",
              "        2.81528868e-02,  3.62134613e-02, -8.63043685e-03, -2.72520203e-02,\n",
              "       -8.89040902e-02,  3.70367616e-02,  1.36179812e-02,  2.59568566e-03,\n",
              "        2.93867067e-02, -3.52998916e-03, -8.17093775e-02,  2.62217522e-02,\n",
              "        3.67520191e-02,  2.90936474e-02, -1.54944230e-02,  7.58748725e-02,\n",
              "       -1.38452686e-02,  4.87547293e-02,  1.97304692e-02, -1.96478702e-02,\n",
              "        4.78665642e-02, -1.86682362e-02, -1.49083473e-02,  2.91417912e-03,\n",
              "        2.38276040e-03, -4.14907783e-02, -4.15751003e-02, -2.82501597e-02,\n",
              "        2.13259738e-02,  2.27570198e-02, -1.02229781e-01, -7.69441426e-02,\n",
              "       -9.65487212e-03,  3.59709114e-02, -2.00208090e-03, -2.96489242e-02,\n",
              "        1.05026765e-02, -3.50029841e-02,  5.04593085e-03,  2.15882808e-03,\n",
              "        2.60717794e-02, -2.61069951e-03,  6.32267445e-03, -3.37637402e-02,\n",
              "        1.85635034e-02, -2.57156845e-02, -1.33219492e-02, -2.28665899e-02,\n",
              "        1.38667459e-02,  1.18890302e-02, -8.75930395e-03,  1.18011683e-02,\n",
              "        1.34138195e-02, -1.48967048e-03, -1.11360950e-02,  1.93008373e-03,\n",
              "        8.67043808e-03,  4.09859680e-02,  3.36319692e-02,  2.19492819e-02,\n",
              "        3.50118354e-02, -2.32928861e-02,  2.00256538e-02, -1.24604749e-02,\n",
              "       -5.87612018e-02,  7.07165617e-03,  1.67010706e-02,  3.25341262e-02,\n",
              "        4.24127765e-02, -4.05548140e-02, -3.38625796e-02, -1.04512066e-01,\n",
              "        4.30115387e-02, -6.46033650e-03, -2.24256199e-02, -1.36884274e-02,\n",
              "       -6.92015747e-03,  5.67797460e-02,  1.73166394e-02, -7.71407178e-03,\n",
              "        7.07845262e-04,  1.53771993e-02, -2.36375607e-04, -3.76079008e-02,\n",
              "       -2.03579627e-02, -1.67816300e-02, -9.42970440e-02, -6.04999810e-02,\n",
              "       -1.95922982e-02, -5.47769992e-03,  2.36217845e-02,  2.28909794e-02,\n",
              "        4.37726313e-03, -4.49806862e-02,  6.28202483e-02, -1.27429189e-02,\n",
              "       -2.06748601e-02, -5.32713793e-02, -6.92666695e-02,  4.47456688e-02,\n",
              "        4.93172519e-02, -3.00535467e-02,  4.11410118e-04, -3.64535674e-03,\n",
              "        4.47554439e-02,  5.08308746e-02,  8.84258281e-03,  6.02660663e-02],\n",
              "      dtype=float32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 31
        }
      ]
    },
    {
      "metadata": {
        "id": "uZh6r3q9jmsC",
        "colab_type": "code",
        "outputId": "6554abce-d233-4470-ecaf-f54fa39edbac",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1309
        }
      },
      "cell_type": "code",
      "source": [
        "# This should really be called 'transform'\n",
        "d2v_model.infer_vector(['only', 'you', 'can', 'prevent', 'forest', 'fires'])\n",
        "#d2v_model.save(\"d2v.model\")"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([-5.25986170e-03,  6.20769197e-03, -1.01683652e-02, -5.78836463e-02,\n",
              "        1.79207232e-02, -1.84146110e-02,  1.18901152e-02, -2.85868044e-03,\n",
              "        3.72904874e-02, -8.24115239e-03, -5.49141429e-02, -1.02457041e-02,\n",
              "        5.73497303e-02,  6.00016825e-02,  2.72469223e-02, -5.52944746e-03,\n",
              "        1.87095571e-02,  7.51122534e-02, -3.59144323e-02,  4.06571254e-02,\n",
              "        6.52733594e-02, -1.98931377e-02, -9.65229869e-02, -5.96575513e-02,\n",
              "        1.52450688e-02, -9.01546795e-04,  6.92641661e-02, -3.56239476e-03,\n",
              "       -2.81073134e-02,  8.65784939e-03,  7.96083640e-03, -3.13656628e-02,\n",
              "       -6.66712448e-02,  3.86735192e-03,  3.37520503e-02, -1.77835524e-02,\n",
              "        7.14908540e-02,  2.62806658e-02,  9.94402636e-03,  5.36390245e-02,\n",
              "        6.77442551e-02,  5.21438792e-02, -6.52948469e-02, -1.60211080e-03,\n",
              "        3.67415100e-02, -3.69558670e-02, -1.47103285e-02, -5.03770448e-02,\n",
              "        1.23436172e-02, -1.21247582e-02,  3.97851095e-02, -3.88326943e-02,\n",
              "       -4.40634927e-03,  4.03401144e-02,  1.07139638e-02,  5.42199165e-02,\n",
              "       -1.30745685e-02,  6.64285338e-03, -2.18238123e-02,  5.76676615e-02,\n",
              "        6.08998816e-03,  2.19478309e-02, -6.92673996e-02,  5.23021370e-02,\n",
              "        6.98810145e-02,  3.25645581e-02, -7.68551370e-04,  4.21721563e-02,\n",
              "        1.28329424e-02,  5.42199500e-02, -7.70194232e-02,  9.78249311e-02,\n",
              "        3.07940673e-02, -1.08364217e-01,  1.87317387e-03,  3.49823609e-02,\n",
              "        9.05696489e-03,  4.64661829e-02,  1.55193564e-02, -6.19804487e-02,\n",
              "       -2.89951894e-03,  9.78952870e-02,  4.13970510e-03, -4.70146313e-02,\n",
              "       -4.07383358e-03,  2.25126259e-02, -9.56913643e-03,  6.13306351e-02,\n",
              "       -3.55873629e-02,  9.26621854e-02, -3.87896821e-02, -2.67855432e-02,\n",
              "        3.65697243e-03,  6.24871766e-03, -4.32378165e-02, -1.21145928e-02,\n",
              "       -2.17823312e-02, -3.43470015e-02, -1.62229873e-02, -4.51569147e-02,\n",
              "       -1.78960729e-02, -8.83836746e-02,  3.47833447e-02,  2.88886279e-02,\n",
              "        6.17143512e-02,  7.12560639e-02,  1.56591553e-02, -3.79383564e-02,\n",
              "       -1.44287236e-02,  2.64031831e-02, -4.04758453e-02, -4.70494591e-02,\n",
              "       -2.26869006e-02,  1.95095390e-02,  1.28756650e-02, -8.21352378e-02,\n",
              "        3.93910296e-02,  1.16380462e-02, -2.14980144e-04, -4.41156290e-02,\n",
              "       -3.50307040e-02,  1.89675149e-02, -8.81025381e-03, -2.27659997e-02,\n",
              "        6.73632771e-02,  3.81029733e-02,  5.53457718e-03,  1.32408783e-01,\n",
              "        3.41172405e-02, -1.67728495e-02, -6.18412085e-02,  1.01649314e-02,\n",
              "        3.36102472e-04, -3.67825590e-02,  9.96006280e-02,  5.59839793e-02,\n",
              "       -1.36819817e-02, -4.17501405e-02, -1.66656952e-02, -7.68334791e-02,\n",
              "       -6.12572022e-02, -6.72241077e-02, -3.71264368e-02, -3.25615294e-02,\n",
              "        5.89843765e-02,  5.55035062e-02, -2.42795721e-02,  1.01355109e-02,\n",
              "        1.59960019e-03, -2.12449785e-02, -7.82558322e-02,  4.73514237e-02,\n",
              "       -1.38562722e-02,  1.95457824e-02, -4.84100878e-02,  6.40314668e-02,\n",
              "       -1.51374079e-02,  2.63163112e-02, -4.24863361e-02, -8.21122006e-02,\n",
              "       -1.14351809e-02, -1.79245155e-02,  4.60356809e-02, -3.45353745e-02,\n",
              "        7.92451482e-03, -9.18928981e-02, -1.92635730e-02, -2.42247246e-02,\n",
              "       -3.74436774e-03, -1.24567309e-02,  1.51526313e-02,  1.52899383e-03,\n",
              "        4.33933772e-02, -7.76311979e-02,  2.59802751e-02, -8.13140650e-04,\n",
              "        1.01284564e-01,  3.41248475e-02,  3.13222818e-02, -2.55930424e-02,\n",
              "       -5.37562370e-02,  1.85479280e-02,  5.82309067e-03,  2.79950164e-02,\n",
              "        3.82707752e-02, -4.34666462e-02, -5.02789021e-02,  2.40835641e-02,\n",
              "        3.55915613e-02, -8.58845040e-02,  3.33086029e-02, -4.09137197e-02,\n",
              "       -3.33532058e-02,  2.24040709e-02, -7.28650833e-04,  4.96650767e-03,\n",
              "       -2.88010426e-02, -6.52276387e-04,  3.84909436e-02,  2.57544722e-02,\n",
              "        5.07369563e-02, -4.01870124e-02, -1.86064124e-01,  2.10228376e-02,\n",
              "        7.29388148e-02,  2.27151532e-02,  5.90418279e-03,  4.87881117e-02,\n",
              "       -6.50228485e-02,  4.22461778e-02,  1.13523481e-02,  1.02894921e-02,\n",
              "        8.90495628e-03,  1.06722377e-02, -6.52323440e-02, -6.88312724e-02,\n",
              "       -2.53162421e-02, -4.12583835e-02, -3.43290791e-02, -8.01591724e-02,\n",
              "        1.31770447e-02,  5.67568056e-02, -1.43552661e-01, -1.24189639e-02,\n",
              "       -2.35090349e-02,  7.89906532e-02,  2.45313048e-02, -8.55286345e-02,\n",
              "       -2.47602561e-03, -3.26568969e-02,  3.87664768e-03, -6.53019622e-02,\n",
              "        4.02425639e-02,  8.12125113e-03, -3.78686637e-02,  8.13986640e-04,\n",
              "        4.74605747e-02, -7.97621440e-03,  4.05373834e-02,  2.56425794e-02,\n",
              "        4.21776809e-02, -1.15287341e-02, -8.91607627e-03,  4.93725426e-02,\n",
              "       -8.81178118e-03,  3.59257087e-02,  2.37824675e-02, -8.39455242e-06,\n",
              "        3.80024686e-02,  3.47670726e-02, -6.21945746e-02, -3.63599844e-02,\n",
              "        1.36676850e-02,  9.95527767e-03,  1.67769045e-02, -3.14950780e-03,\n",
              "       -6.93426430e-02,  8.32225531e-02,  5.14873862e-02,  1.99932940e-02,\n",
              "        1.55882153e-03, -5.93908876e-02, -1.59183312e-02,  6.61124068e-04,\n",
              "        4.60416824e-02, -4.16100547e-02,  1.35543570e-02, -5.52192517e-03,\n",
              "        9.21242498e-03,  9.49413627e-02,  2.04978827e-02,  3.51219848e-02,\n",
              "       -1.49750174e-03,  4.16393988e-02,  5.03832512e-02, -4.52152044e-02,\n",
              "       -3.14806029e-02, -4.98456471e-02, -4.22924161e-02, -1.91559121e-02,\n",
              "        2.07975488e-02,  2.47007795e-02,  3.04747559e-02,  2.27417368e-02,\n",
              "        3.18644531e-02,  1.16457539e-02,  7.62006044e-02, -4.82966490e-02,\n",
              "        1.38633857e-02, -4.96495292e-02, -1.21594213e-01,  2.17436682e-02,\n",
              "       -2.55117342e-02,  8.60717241e-03, -1.81129407e-02, -2.63627693e-02,\n",
              "        3.00363246e-02, -1.83123443e-02, -3.23575623e-02,  7.80134201e-02],\n",
              "      dtype=float32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 32
        }
      ]
    },
    {
      "metadata": {
        "id": "rfMb-Fbyr9Nx",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "This represents the paragraph just like another word in the collection."
      ]
    },
    {
      "metadata": {
        "id": "94Yq3wffa09W",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Evaluation\n",
        "\n",
        "We'll look at two ways to evaluate our models.\n",
        "\n",
        "1.   Finding similar documents\n",
        "2.   Word analogies\n",
        "\n",
        "These are both extrinsic evaluations.  Other extrinsic evaluations include using them as part of supervised learning, such as text classification."
      ]
    },
    {
      "metadata": {
        "id": "ZxxhnFVjtkVX",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Find similar documents revisited ###\n",
        "\n",
        "One application of this is finding related reddit posts for a given document or string. For example, to create a 'Reddit widget' to embed in a webpage that shows related content from Reddit. \n",
        "\n",
        "We'll use our representation of documents to find similar posts and to query the documents.\n"
      ]
    },
    {
      "metadata": {
        "id": "WEQxi7MkOeB7",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#Solution \n",
        "\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        " \n",
        "# A function that given an input query item returns the top-k most similar items \n",
        "# by their cosine similarity.\n",
        "def find_similar(query_vector, vd_matrix, top_k = 5):\n",
        "    cosine_similarities = cosine_similarity(query_vector, vd_matrix).flatten()\n",
        "    related_doc_indices = cosine_similarities.argsort()[::-1]\n",
        "    return [(index, cosine_similarities[index]) for index in related_doc_indices][0:top_k]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "swKnLZfCuIZp",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Find the top 10 most similar posts based on cosine similarity in the word vector representation."
      ]
    },
    {
      "metadata": {
        "id": "m4XwBaTnYUmi",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Try this with both the glove and w2v embeddings."
      ]
    },
    {
      "metadata": {
        "id": "IDEqol2DV3T4",
        "colab_type": "code",
        "outputId": "e3085937-9551-46ec-e083-35834b4792db",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 221
        }
      },
      "cell_type": "code",
      "source": [
        "doc = tokenize_normalize('end of the world as we know it')\n",
        "\n",
        "# Glove vectorizer\n",
        "vectorizer = glove_vectorizer\n",
        "matrix = glove_post_vector_matrix\n",
        "\n",
        "# Reddit w2v\n",
        "#vectorizer = reddit_vectorizer\n",
        "#matrix = reddit_post_vector_matrix\n",
        "\n",
        "transformed = vectorizer.transform([doc])\n",
        "\n",
        "query_vector = transformed[0:1]\n",
        "print(\"\\nSimilar posts:\")\n",
        "for index, score in find_similar(query_vector, matrix, 10):\n",
        "  post_contents = post_frame.iloc[index]['body'].replace('\\n', '')\n",
        "  post_limited = (post_contents[:75] + '..') if len(post_contents) > 75 else post_contents\n",
        "  print(score, index, post_limited)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Similar posts:\n",
            "0.986180196887454 13929 I'm waiting for the end of our world as we know it.\n",
            "0.9754958123360006 54588 i like the combat part of the game, and thats what i do most of the time\n",
            "0.9752114562100662 79082 I think it's important to move on and grow as an organization. If we really..\n",
            "0.9751531148576654 108016 I have yet to have this answered:With this being an exclusive to a store in..\n",
            "0.9745856145493386 93230 I've applied to be a volunteer for the Women's World Cup next summer. Has a..\n",
            "0.9740005964759789 36762 > After what amount of time can a game be made about unfortunate topics lik..\n",
            "0.9737832116518266 109166 I don't think the end result will be much surprise, more the information so..\n",
            "0.9734281338618875 38473 I swear it's hard to believe the latter is true. It seems like we let oppon..\n",
            "0.973413351785116 32252 I have this feeling that we won't see anything of Jon before the very end o..\n",
            "0.9733660047299328 110010 I know we might not know the overall sales head for the game itself but was..\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "mYnEn9IrYF-D",
        "colab_type": "code",
        "outputId": "42defecb-d627-4107-82ae-b2ce37030eaa",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 258
        }
      },
      "cell_type": "code",
      "source": [
        "import random as rand\n",
        "post_index = 1000\n",
        "post_index = rand.randint(0, len(all_posts_tokenized))\n",
        "tokens = all_posts_tokenized[post_index]\n",
        "print(tokens)\n",
        "\n",
        "# Transform our string using the vocabulary\n",
        "transformed = vectorizer.transform([tokens])\n",
        "doc = transformed[0:1]\n",
        "\n",
        "print(\"\\nSimilar posts:\")\n",
        "for index, score in find_similar(doc, matrix, 10):\n",
        "  post_contents = post_frame.iloc[index]['body'].replace('\\n', '')\n",
        "  post_limited = (post_contents[:150] + '..') if len(post_contents) > 150 else post_contents\n",
        "  print(score, index, post_limited)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['it', 'you', 'not', 'killing', 'murlocs']\n",
            "\n",
            "Similar posts:\n",
            "1.0000000000000002 61894 It's you not killing murlocs...\n",
            "0.9593286334159343 1536 If you killed him for it, I think its okay.\n",
            "0.957443996883571 74809 overwatered... and you'll want to kill it if it's a him anyway so there is that\n",
            "0.9560513096360399 61287 That's unsettling. I'm not really into killing people for any reason.\n",
            "0.9536304095476625 60725 Implement something like \"guilt meter\" or something that is negatively affected by killing people. Because this is just a game, there's no moral impli..\n",
            "0.9531639269785182 11619 I like to kill enemies.  But when i play strikes it is not to kill enemies. It is for das loot.If you like killing enemies there are plenty of \"story\"..\n",
            "0.952163249182143 9054 People do what they like doing. As long as it's not harming someone else, who am I to say they're wrong for it or that they shouldn't do it? Do what y..\n",
            "0.949987797536188 67830 No. What are you thinking?You should act in game how you act in person. If someone spilled water on your shirt you don't explode on them.Also, you don..\n",
            "0.9496875455019751 92430 if you try something and decide it wasn't fun, does that mean you're burned out?  \n",
            "0.9492379280304835 60126 If you don't return it you're a heel. There's no moral conflict here whatsoever. You don't know what the circumstances are for why it was on the groun..\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "rsK3oNBVhZlc",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "**Optional**: The code below does the same computation on the random post tokens."
      ]
    },
    {
      "metadata": {
        "id": "bDYO4OzohUAO",
        "colab_type": "code",
        "outputId": "8b156221-1948-4ab4-ba61-c51045f10121",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 258
        }
      },
      "cell_type": "code",
      "source": [
        "#Compare with doc2vec\n",
        "\n",
        "inferred_vector = d2v_model.infer_vector(tokens)\n",
        "print(tokens)\n",
        "#print(inferred_vector)\n",
        "similar = d2v_model.docvecs.most_similar([inferred_vector], topn=10)\n",
        "\n",
        "print(\"\\nSimilar posts:\")\n",
        "for (label, score) in similar:\n",
        "  post_contents = post_frame.iloc[label]['body'].replace('\\n', '')\n",
        "  post_limited = (post_contents[:150] + '..') if len(post_contents) > 150 else post_contents\n",
        "  print(score, index, post_limited)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['it', 'you', 'not', 'killing', 'murlocs']\n",
            "\n",
            "Similar posts:\n",
            "0.8076038956642151 60126 TALK TO YOUR DOCTOR\n",
            "0.8051517605781555 60126 This is awesome! Thank you!\n",
            "0.7989120483398438 60126 EDIT: Thanks for the gold\n",
            "0.7988681793212891 60126 Like [this?](http://i.imgur.com/HKv6Q.png)\n",
            "0.7975093126296997 60126 Sent PM for more info.\n",
            "0.7962121367454529 60126 Have you tried to [delete the app?](http://www.ehow.com/how_8499789_uninstall-vizio-widgets.html)\n",
            "0.7954484224319458 60126 That would be nice\n",
            "0.7953639030456543 60126 June of this yearhttp://www.cbssports.com/nba/eye-on-basketball/24585305/wolves-ricky-rubio-i-would-like-to-be-on-a-winning-team\n",
            "0.7950241565704346 60126 That makes sense. Thanks for the insight. \n",
            "0.7949143648147583 60126 This is fantastic! Thank you!\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "ylQ_PRBdl21E",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Compare the similarity of Glove vs. Reddit vectorizers on this task.  Are the results different, which one do you think is more effective? \n",
        "\n",
        "In the current case, it looks like the doc2vec vectors are not (yet) optimal.  They may need additional training or different parameters to be very effective."
      ]
    },
    {
      "metadata": {
        "id": "D7Ntn894nap0",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "###Extrinsic evaluation with word analogies ###\n",
        "We've seen how to combine word vectors and find the most similar words.  \n",
        "\n",
        "Recall: glove_model.wv.doesnt_match(\"apple pear orange car\".split())\n",
        "\n",
        "Revisit this problem and try implementing a solution yourself. After you're done, you could look at the source code in gensim to see how your approach compares.\n"
      ]
    },
    {
      "metadata": {
        "id": "9rsOT_cSe5PW",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import logging\n",
        "logging.basicConfig(format='%(asctime)s : %(levelname)s : %(message)s', level=logging.INFO)\n",
        "!wget https://raw.githubusercontent.com/RaRe-Technologies/gensim/develop/gensim/test/test_data/questions-words.txt\n",
        "\n",
        "glove_model.wv.evaluate_word_analogies('questions-words.txt')\n",
        "model.wv.evaluate_word_analogies('questions-words.txt')\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "oW3ciNtEbL-T",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Note: this may be slow for the 300D model."
      ]
    },
    {
      "metadata": {
        "id": "zRFU78rJfmt4",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "The reddit model accuracy."
      ]
    },
    {
      "metadata": {
        "id": "JcpFGG90b0LB",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "model.wv.evaluate_word_analogies('questions-words.txt')\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "jbPnbSD4cSWD",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "glove_model.wv.evaluate_word_analogies('questions-words.txt')\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "JVWRA1Zlyyqp",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "We have just scratched the surface of word embeddings. \n",
        "\n",
        "See this great post about the rise of [BERT, ELMo, and others](http://jalammar.github.io/illustrated-bert/).  These new embedding models that perform the task of language modeling are state-of-the-art and leading to a new revolution in NLP effectiveness. \n"
      ]
    },
    {
      "metadata": {
        "id": "_1BkhgGWfI-J",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Wrapup\n",
        "\n",
        "Take the [Moodle quiz](https://moodle.gla.ac.uk/mod/feedback/view.php?id=1118007) for this lab and let us know what you think."
      ]
    },
    {
      "metadata": {
        "id": "hBs_5JNxhkDS",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## (Optional) Extra exercises \n",
        "\n",
        "### Modify the document vector representation ###\n",
        "\n",
        "Experiment with other ways to combining the word vectors.  \n",
        "\n",
        "*   What about taking max?\n",
        "*   Add IDF weighting to create a weighted average\n",
        "*   Remove stopwords or other non-informative words\n",
        "\n",
        "### Modify embedding hyper-parameters ###\n",
        "Retrain the reddit model with different parameters. For example try varying some of the following:\n",
        "\n",
        "*   Dimension of embeddings\n",
        "*   Window size \n",
        "*   Skipgram vs CBOW\n",
        "*   Iterations or learning rates\n",
        "\n",
        "\n",
        "Compare the embeddings on some of the examples. How similar are they?  How would you select a set of parameters that performs the 'best'? \n",
        "\n",
        "Evaluate the model on the word analogy task. "
      ]
    },
    {
      "metadata": {
        "id": "RB8CdPx9LiKy",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Playing with vizualizations ###"
      ]
    },
    {
      "metadata": {
        "id": "vYjfYgwqqoBv",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "We can use a WordCloud to vizualize the similar words. You could use the popular WordCloud python library. (And we'll use a nice font from Google Fonts.)"
      ]
    },
    {
      "metadata": {
        "id": "o6YsbXCZlGFN",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "!wget https://storage.googleapis.com/tad2018/OpenSansCondensed-Bold.ttf\n",
        "!pip install wordcloud\n",
        "\n",
        "# Below is optional code to create a 'mask' to put the wordcloud into a cool shape.\n",
        "!wget https://storage.googleapis.com/tad2018/reddit-mask.png\n",
        "\n",
        "from PIL import Image\n",
        "from os import path\n",
        "import os \n",
        "\n",
        "reddit_mask = np.array(Image.open(path.join(os.getcwd(), \"reddit-mask.png\")))\n",
        "tad_mask = np.array(Image.open(path.join(os.getcwd(), \"tad-mask3.png\")))\n",
        "\n",
        "# !wget https://storage.googleapis.com/tad2018/tad-mask3.png"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "cfjImZvqQFpb",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "terms = model.wv.most_similar(positive=['lit', 'thanks'], topn=1000)\n",
        "print(terms)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "3grnP90trHDo",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from os import path\n",
        "import matplotlib.pyplot as plt\n",
        "from wordcloud import WordCloud\n",
        "\n",
        "# Convert the similarity score into an integer count, N.\n",
        "# Repeat the word in a space separated string N times.\n",
        "def terms_to_wordcounts(terms, multiplier=1000):\n",
        "    <Your Code here>\n",
        "\n",
        "term_counts = terms_to_wordcounts(terms)\n",
        "\n",
        "wc = WordCloud(font_path='/content/OpenSansCondensed-Bold.ttf',\n",
        "                      width=2048,\n",
        "                      height=2048,\n",
        "                      max_words=1000,\n",
        "                      mask=reddit_mask, # optional mask\n",
        "                      background_color=\"white\").generate(term_counts)\n",
        "\n",
        "plt.imshow(wc)\n",
        "plt.axis(\"off\")\n",
        "plt.show()\n",
        "plt.savefig(\"terms1\")\n",
        "plt.close()  "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "r-hOiFKaPopK",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#Solution \n",
        "\n",
        "from os import path\n",
        "import matplotlib.pyplot as plt\n",
        "from wordcloud import WordCloud\n",
        "\n",
        "def terms_to_wordcounts(terms, multiplier=1000):\n",
        "  counts = (i[0]+\" \" * int(multiplier*i[1]) for i in terms)\n",
        "  return  \" \".join(counts)\n",
        "\n",
        "\n",
        "term_counts = terms_to_wordcounts(terms)\n",
        "\n",
        "wc = WordCloud(font_path='/content/OpenSansCondensed-Bold.ttf',\n",
        "                      width=2048,\n",
        "                      height=2048,\n",
        "                      max_words=1000,\n",
        "                      mask=reddit_mask, # optional mask\n",
        "                      background_color=\"white\").generate(term_counts)\n",
        "\n",
        "plt.imshow(wc)\n",
        "plt.axis(\"off\")\n",
        "plt.show()\n",
        "plt.savefig(\"terms1\")\n",
        "plt.close()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "01HzDyNSlb86",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "wc.to_file(\"terms.png\")\n",
        "\n",
        "from google.colab import files\n",
        "files.download('terms.png')"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}